{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertofiguz/rl-walking/blob/main/walker_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Changes\n",
        "v2:   \n",
        "- change reward to give positive reward from 0 to screen width (loss will give a better viz?)\n",
        "- log average reward of episode"
      ],
      "metadata": {
        "id": "mUTnYTunh67S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame\n",
        "!pip install pymunk\n",
        "!pip install tensorflow\n",
        "!pip install gym\n",
        "!pip install wandb\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install google-cloud-secret-manager\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install 'imageio==2.4.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fixhcg7xwNVL",
        "outputId": "b0aab0da-7ea7-4dc1-c395-c172d3289545"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: pymunk in /usr/local/lib/python3.7/dist-packages (6.2.1)\n",
            "Requirement already satisfied: cffi>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from pymunk) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.15.0->pymunk) (2.21)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.4)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.10)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.19.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.6)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n",
            "Requirement already satisfied: google-cloud-secret-manager in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-secret-manager) (0.12.3)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.28.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-secret-manager) (2.5.0)\n",
            "Requirement already satisfied: libcst>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-secret-manager) (0.4.1)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-secret-manager) (1.20.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (3.19.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (1.54.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (1.44.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (1.44.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (4.8)\n",
            "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-secret-manager) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-secret-manager) (3.10.0.2)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-secret-manager) (0.7.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-secret-manager) (3.0.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-secret-manager) (0.4.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: imageio==2.4.0 in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (1.21.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ktnsHlqqOMm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "base_path = \"/content/drive/MyDrive/Final_Project/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ackAautX0iF",
        "outputId": "6f1b8cda-c125-4cc4-d6b0-a8867b4dbdd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import gym\n",
        "import math\n",
        "import wandb\n",
        "import pymunk\n",
        "import base64\n",
        "import pygame\n",
        "import imageio\n",
        "import IPython\n",
        "import numpy as np\n",
        "import pyvirtualdisplay\n",
        "import tensorflow as tf\n",
        "import pymunk.pygame_util\n",
        "from gym import Env\n",
        "from PIL import Image\n",
        "from gym import logger\n",
        "from numpy import append\n",
        "from tensorflow import keras\n",
        "from collections import deque\n",
        "from google.colab import auth\n",
        "from wandb.keras import WandbCallback\n",
        "from google.cloud import secretmanager\n",
        "from gym.spaces import Box, MultiDiscrete\n",
        "from tensorflow.keras.models import Model\n",
        "from random import randint, random, sample\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input"
      ],
      "metadata": {
        "id": "LAMIobPEMyy6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "bceb9d0a-7a93-4646-ba3f-6e572066641f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d08e6e57834c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "client = secretmanager.SecretManagerServiceClient()\n",
        "secret_name = \"wandb-key\" # => To be replaced with your secret name\n",
        "project_id = '786036037251' # => To be replaced with your GCP Project\n",
        "resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\" \n",
        "response = client.access_secret_version(request={\"name\": resource_name})\n",
        "wandb.login(key=response.payload.data.decode('UTF-8'))"
      ],
      "metadata": {
        "id": "ZkUStnPdDjZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
      ],
      "metadata": {
        "id": "n50Y5NtBj-lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Walker"
      ],
      "metadata": {
        "id": "xGLDIEsjUv9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "screen_width = 1900\n",
        "screen_height = 960\n",
        "\n",
        "class Robot():\n",
        "    def __init__(self, space):\n",
        "        \n",
        "        self.tick = 0\n",
        "\n",
        "        moment = 10\n",
        "        friction = 0.5\n",
        "\n",
        "        self.shape = pymunk.Poly.create_box(None, (50, 100))\n",
        "        body_moment = pymunk.moment_for_poly(moment, self.shape.get_vertices())\n",
        "        self.body = pymunk.Body(moment, body_moment)\n",
        "        \n",
        "        self.body.position = (200, 350)\n",
        "        self.shape.body = self.body\n",
        "        self.shape.color = (150, 150, 150, 0)\n",
        "\n",
        "        head_moment = pymunk.moment_for_circle(moment, 0, 30)\n",
        "        self.head_body = pymunk.Body(moment, head_moment)\n",
        "        self.head_body.position = (self.body.position.x, self.body.position.y+80)\n",
        "        self.head_shape = pymunk.Circle(self.head_body, 30)\n",
        "        self.head_shape.friction = friction\n",
        "        self.head_joint = pymunk.PivotJoint(self.head_body, self.body, (-5, -30), (-5, 50))\n",
        "        self.head_joint2 = pymunk.PivotJoint(self.head_body, self.body, (5, -30), (5, 50))\n",
        "\n",
        "\n",
        "        arm_size = (100, 20)\n",
        "        self.left_arm_upper_shape = pymunk.Poly.create_box(None, arm_size)\n",
        "        left_arm_upper_moment = pymunk.moment_for_poly(moment, self.left_arm_upper_shape.get_vertices())\n",
        "        self.left_arm_upper_body = pymunk.Body(moment, left_arm_upper_moment)\n",
        "        self.left_arm_upper_body.position = (self.body.position.x-30, self.body.position.y)\n",
        "        self.left_arm_upper_shape.body = self.left_arm_upper_body\n",
        "        self.left_arm_upper_joint = pymunk.PivotJoint(self.left_arm_upper_body, self.body, (arm_size[0] / 2, 0), (-25, 30))\n",
        "        self.la_motor = pymunk.SimpleMotor(self.body, self.left_arm_upper_body, 0)\n",
        "\n",
        "        self.right_arm_upper_shape = pymunk.Poly.create_box(None, arm_size)\n",
        "        right_arm_upper_moment = pymunk.moment_for_poly(moment, self.right_arm_upper_shape.get_vertices())\n",
        "        self.right_arm_upper_body = pymunk.Body(moment, right_arm_upper_moment)\n",
        "        self.right_arm_upper_body.position = (self.body.position.x+30, self.body.position.y)\n",
        "        self.right_arm_upper_shape.body = self.right_arm_upper_body\n",
        "        self.right_arm_upper_joint = pymunk.PivotJoint(self.right_arm_upper_body, self.body, (-arm_size[0] / 2, 0), (25, 30))\n",
        "        self.ra_motor = pymunk.SimpleMotor(self.body, self.right_arm_upper_body, 0)\n",
        "\n",
        "        thigh_size = (30, 60)\n",
        "        self.lu_shape = pymunk.Poly.create_box(None, thigh_size)\n",
        "        lu_moment = pymunk.moment_for_poly(moment, self.lu_shape.get_vertices())\n",
        "        self.lu_body = pymunk.Body(moment, lu_moment)\n",
        "        self.lu_body.position = (self.body.position.x-20, self.body.position.y-50)\n",
        "        self.lu_shape.body = self.lu_body\n",
        "        self.lu_shape.friction = friction\n",
        "        self.lu_joint = pymunk.PivotJoint(self.lu_body, self.body, (0, thigh_size[1] / 2), (-20, -50))\n",
        "        self.lu_motor = pymunk.SimpleMotor(self.body, self.lu_body, 0)\n",
        "\n",
        "        self.ru_shape = pymunk.Poly.create_box(None, thigh_size)\n",
        "        ru_moment = pymunk.moment_for_poly(moment, self.ru_shape.get_vertices())\n",
        "        self.ru_body = pymunk.Body(moment, ru_moment)\n",
        "        self.ru_body.position = (self.body.position.x+20, self.body.position.y - 50)\n",
        "        self.ru_shape.body = self.ru_body\n",
        "        self.ru_shape.friction = friction\n",
        "        self.ru_joint = pymunk.PivotJoint(self.ru_body, self.body, (0, thigh_size[1] / 2), (20, -50))\n",
        "        self.ru_motor = pymunk.SimpleMotor(self.body, self.ru_body, 0)\n",
        "\n",
        "        leg_size = (20, 70)\n",
        "        self.ld_shape = pymunk.Poly.create_box(None, leg_size)\n",
        "        ld_moment = pymunk.moment_for_poly(moment, self.ld_shape.get_vertices())\n",
        "        self.ld_body = pymunk.Body(moment, ld_moment)\n",
        "        self.ld_body.position = (self.lu_body.position.x, self.lu_body.position.y - 100)\n",
        "        self.ld_shape.body = self.ld_body\n",
        "        self.ld_shape.friction = friction\n",
        "        self.ld_joint = pymunk.PivotJoint(self.ld_body, self.lu_body, (0, leg_size[1] / 2), (0, -thigh_size[1] / 2))\n",
        "        self.ld_motor = pymunk.SimpleMotor(self.lu_body, self.ld_body, 0)\n",
        "\n",
        "        self.rd_shape = pymunk.Poly.create_box(None, leg_size)\n",
        "        rd_moment = pymunk.moment_for_poly(moment, self.rd_shape.get_vertices())\n",
        "        self.rd_body = pymunk.Body(moment, rd_moment)\n",
        "        self.rd_body.position = (self.ru_body.position.x, self.ru_body.position.y - 100)\n",
        "        self.rd_shape.body = self.rd_body\n",
        "        self.rd_shape.friction = friction\n",
        "        self.rd_joint = pymunk.PivotJoint(self.rd_body, self.ru_body, (0, leg_size[1] / 2), (0, -thigh_size[1] / 2))\n",
        "        self.rd_motor = pymunk.SimpleMotor(self.ru_body, self.rd_body, 0)\n",
        "\n",
        "\n",
        "        foot_size = (45, 20)\n",
        "        self.lf_shape = pymunk.Poly.create_box(None, foot_size)\n",
        "        rd_moment = pymunk.moment_for_poly(moment, self.lf_shape.get_vertices())\n",
        "        self.lf_body = pymunk.Body(moment, rd_moment)\n",
        "        self.lf_body.position = (self.ld_body.position.x + foot_size[0]/2, self.ld_body.position.y + (foot_size[1]/2 + leg_size[1]/2))\n",
        "        self.lf_shape.body = self.lf_body\n",
        "        self.lf_shape.friction = friction\n",
        "        self.lf_shape.elasticity = 0.1\n",
        "        self.lf_joint = pymunk.PivotJoint(self.ld_body, self.lf_body, (-5, -leg_size[1] / 2), (-foot_size[0]/2 + 10, foot_size[1]/2))\n",
        "        self.lf_motor = pymunk.SimpleMotor(self.ld_body, self.lf_body, 0)\n",
        "\n",
        "        self.rf_shape = pymunk.Poly.create_box(None, foot_size)\n",
        "        rd_moment = pymunk.moment_for_poly(moment, self.rf_shape.get_vertices())\n",
        "        self.rf_body = pymunk.Body(moment, rd_moment)\n",
        "        self.rf_body.position = (self.rd_body.position.x + foot_size[0]/2, self.rd_body.position.y + (foot_size[1]/2 + leg_size[1]/2))\n",
        "        self.rf_shape.body = self.rf_body\n",
        "        self.rf_shape.friction = friction\n",
        "        self.rf_shape.elasticity = 0.1\n",
        "        self.rf_joint = pymunk.PivotJoint(self.rd_body, self.rf_body, (-5, -leg_size[1] / 2), (-foot_size[0]/2 + 10, foot_size[1]/2))\n",
        "        self.rf_motor = pymunk.SimpleMotor(self.rd_body, self.rf_body, 0)\n",
        "\n",
        "        space.add(self.body, self.shape, self.head_body, self.head_shape, self.head_joint, self.head_joint2)\n",
        "        space.add(self.left_arm_upper_body, self.left_arm_upper_shape, self.left_arm_upper_joint, self.la_motor)\n",
        "        space.add(self.right_arm_upper_body, self.right_arm_upper_shape, self.right_arm_upper_joint, self.ra_motor)\n",
        "        space.add(self.lu_body, self.lu_shape, self.lu_joint, self.lu_motor)\n",
        "        space.add(self.ru_body, self.ru_shape, self.ru_joint, self.ru_motor)\n",
        "        space.add(self.ld_body, self.ld_shape, self.ld_joint, self.ld_motor)\n",
        "        space.add(self.rd_body, self.rd_shape, self.rd_joint, self.rd_motor)\n",
        "        space.add(self.lf_body, self.lf_shape, self.lf_joint, self.lf_motor)\n",
        "        space.add(self.rf_body, self.rf_shape, self.rf_joint, self.rf_motor)\n",
        "\n",
        "\n",
        "        shape_filter = pymunk.ShapeFilter(group=1)\n",
        "        self.shape.filter = shape_filter\n",
        "        self.head_shape.filter = shape_filter\n",
        "        self.left_arm_upper_shape.filter = shape_filter\n",
        "        self.right_arm_upper_shape.filter = shape_filter\n",
        "        self.lu_shape.filter = shape_filter\n",
        "        self.ru_shape.filter = shape_filter\n",
        "        self.ld_shape.filter = shape_filter\n",
        "        self.rd_shape.filter = shape_filter\n",
        "        self.lf_shape.filter = shape_filter\n",
        "        self.rf_shape.filter = shape_filter\n",
        "\n",
        "        self.lu_flag = False\n",
        "        self.ld_flag = False\n",
        "        self.ru_flag = False\n",
        "        self.rd_flag = False\n",
        "        self.la_flag = False\n",
        "        self.ra_flag = False\n",
        "        self.lf_flag = False\n",
        "        self.rf_flag = False\n",
        "\n",
        "    def get_shapes(self):\n",
        "        body = self.body, self.shape\n",
        "        head = self.head_body, self.head_shape, self.head_joint, self.head_joint2\n",
        "        left_arm = self.left_arm_upper_body, self.left_arm_upper_shape, self.left_arm_upper_joint, self.la_motor\n",
        "        right_arm = self.right_arm_upper_body, self.right_arm_upper_shape, self.right_arm_upper_joint, self.ra_motor\n",
        "        left_up_leg = self.lu_body, self.lu_shape, self.lu_joint, self.lu_motor\n",
        "        left_down_leg = self.ld_body, self.ld_shape, self.ld_joint, self.ld_motor\n",
        "        left_foot = self.lf_body, self.lf_shape, self.lf_joint, self.lf_motor\n",
        "        right_up_leg = self.ru_body, self.ru_shape, self.ru_joint, self.ru_motor\n",
        "        right_down_leg = self.rd_body, self.rd_shape, self.rd_joint, self.rd_motor\n",
        "        right_foot = self.rf_body, self.rf_shape, self.rf_joint, self.rf_motor\n",
        "\n",
        "        return body, head, left_arm, right_arm, left_up_leg, left_down_leg, left_foot, right_up_leg, right_down_leg, right_foot\n",
        "\n",
        "    def get_data(self):\n",
        "        lu = ((360 - math.degrees(self.lu_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        ld = ((360 - math.degrees(self.ld_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        lf = ((360 - math.degrees(self.lf_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        ru = ((360 - math.degrees(self.ru_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        rd = ((360 - math.degrees(self.rd_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        rf = ((360 - math.degrees(self.rf_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        la = ((360 - math.degrees(self.left_arm_upper_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        ra = ((360 - math.degrees(self.right_arm_upper_body.angle)) - (360 - math.degrees(self.body.angle))) / 360.0\n",
        "        return self.body.angle, lu, ld, lf, la, ru, rd, rf, ra\n",
        "\n",
        "\n",
        "    def set_color(self, color, rest_color = (0, 0, 255), shoe_color = (50, 50, 50)):\n",
        "        self.shape.color = color\n",
        "        self.head_shape.color = color\n",
        "        self.left_arm_upper_shape.color = rest_color\n",
        "        self.right_arm_upper_shape.color = rest_color\n",
        "        self.lu_shape.color = rest_color\n",
        "        self.ld_shape.color = rest_color\n",
        "        self.lf_shape.color = shoe_color\n",
        "        self.ru_shape.color = rest_color\n",
        "        self.rd_shape.color = rest_color\n",
        "        self.rf_shape.color = shoe_color\n",
        "\n",
        "    def update(self):\n",
        "        #lu\n",
        "        self.lu_flag = False\n",
        "        if (360 - math.degrees(self.lu_body.angle)) - (360 - math.degrees(self.body.angle)) >= 90 and self.lu_motor.rate > 0:\n",
        "            self.lu_motor.rate = 0\n",
        "            self.lu_flag = True\n",
        "        elif (360 - math.degrees(self.lu_body.angle)) - (360 - math.degrees(self.body.angle)) <= -90 and self.lu_motor.rate < 0:\n",
        "            self.lu_motor.rate = 0\n",
        "            self.lu_flag = True\n",
        "\n",
        "        #ld\n",
        "        self.ld_flag = False\n",
        "        if (360 - math.degrees(self.ld_body.angle)) - (360 - math.degrees(self.lu_body.angle)) >= 90 and self.ld_motor.rate > 0:\n",
        "            self.ld_motor.rate = 0\n",
        "            self.ld_flag = True\n",
        "        elif (360 - math.degrees(self.ld_body.angle)) - (360 - math.degrees(self.lu_body.angle)) <= -90 and self.ld_motor.rate < 0:\n",
        "            self.ld_motor.rate = 0\n",
        "            self.ld_flag = True\n",
        "\n",
        "        #ru\n",
        "        self.ru_flag = False\n",
        "        if (360 - math.degrees(self.ru_body.angle)) - (360 - math.degrees(self.body.angle)) >= 90 and self.ru_motor.rate > 0:\n",
        "            self.ru_motor.rate = 0\n",
        "            self.ru_flag = True\n",
        "        elif (360 - math.degrees(self.ru_body.angle)) - (360 - math.degrees(self.body.angle)) <= -90 and self.ru_motor.rate < 0:\n",
        "            self.ru_motor.rate = 0\n",
        "            self.ru_flag = True\n",
        "\n",
        "        #rd\n",
        "        self.rd_flag = False\n",
        "        if (360 - math.degrees(self.rd_body.angle)) - (360 - math.degrees(self.ru_body.angle)) >= 90 and self.rd_motor.rate > 0:\n",
        "            self.rd_motor.rate = 0\n",
        "            self.rd_flag = True\n",
        "        elif (360 - math.degrees(self.rd_body.angle)) - (360 - math.degrees(self.ru_body.angle)) <= -90 and self.rd_motor.rate < 0:\n",
        "            self.rd_motor.rate = 0\n",
        "            self.rd_flag = True\n",
        "\n",
        "\n",
        "        #lf\n",
        "        self.lf_flag = False\n",
        "        if (360 - math.degrees(self.lf_body.angle)) - (360 - math.degrees(self.ld_body.angle)) >= 90 and self.lf_motor.rate > 0:\n",
        "            self.lf_motor.rate = 0\n",
        "            self.lf_flag = True\n",
        "        elif (360 - math.degrees(self.lf_body.angle)) - (360 - math.degrees(self.ld_body.angle)) <= -45 and self.lf_motor.rate < 0:\n",
        "            self.lf_motor.rate = 0\n",
        "            self.lf_flag = True\n",
        "\n",
        "\n",
        "        #rf\n",
        "        self.rf_flag = False\n",
        "        if (360 - math.degrees(self.rf_body.angle)) - (360 - math.degrees(self.rd_body.angle)) >= 90 and self.rf_motor.rate > 0:\n",
        "            self.rf_motor.rate = 0\n",
        "            self.rf_flag = True\n",
        "        elif (360 - math.degrees(self.rf_body.angle)) - (360 - math.degrees(self.rd_body.angle)) <= -45 and self.rf_motor.rate < 0:\n",
        "            self.rf_motor.rate = 0\n",
        "            self.rf_flag = True\n",
        "\n",
        "\n",
        "    def add_space(self, space):\n",
        "        space.add(self.body, self.shape, self.head_body, self.head_shape, self.head_joint)\n",
        "        space.add(self.left_arm_upper_body, self.left_arm_upper_shape, self.left_arm_upper_joint, self.la_motor)\n",
        "        space.add(self.right_arm_upper_body, self.right_arm_upper_shape, self.right_arm_upper_joint, self.ra_motor)\n",
        "        space.add(self.lu_body, self.lu_shape, self.lu_joint, self.lu_motor)\n",
        "        space.add(self.ru_body, self.ru_shape, self.ru_joint, self.ru_motor)\n",
        "        space.add(self.ld_body, self.ld_shape, self.ld_joint, self.ld_motor)\n",
        "        space.add(self.rd_body, self.rd_shape, self.rd_joint, self.rd_motor)\n",
        "        space.add(self.lf_body, self.lf_shape, self.lf_joint, self.lf_motor)\n",
        "        space.add(self.rf_body, self.rf_shape, self.rf_joint, self.rf_motor)\n",
        "\n",
        "    def set_position(self, x):\n",
        "        self.body._set_position((self.body.position.x - x, self.body.position.y))\n",
        "        self.head_body._set_position((self.head_body.position.x - x, self.head_body.position.y))\n",
        "        self.left_arm_upper_body._set_position((self.left_arm_upper_body.position.x - x, self.left_arm_upper_body.position.y))\n",
        "        self.right_arm_upper_body._set_position((self.right_arm_upper_body.position.x - x, self.right_arm_upper_body.position.y))\n",
        "\n",
        "        self.lu_body._set_position((self.lu_body.position.x - x, self.lu_body.position.y))\n",
        "        self.ru_body._set_position((self.ru_body.position.x - x, self.ru_body.position.y))\n",
        "        self.ld_body._set_position((self.ld_body.position.x - x, self.ld_body.position.y))\n",
        "        self.rd_body._set_position((self.rd_body.position.x - x, self.rd_body.position.y))\n",
        "        self.lf_body._set_position((self.lf_body.position.x - x, self.lf_body.position.y))\n",
        "        self.rf_body._set_position((self.rf_body.position.x - x, self.rf_body.position.y))\n",
        "\n",
        "    def add_land(self,space):\n",
        "        body = pymunk.Body(body_type=pymunk.Body.STATIC)\n",
        "        body.position = (0, 100)\n",
        "        land = pymunk.Segment(body, (0, 50), (99999, 50), 10)\n",
        "        land.friction = 0.5\n",
        "        land.elasticity = 0.1\n",
        "        space.add(body, land)\n",
        "\n",
        "    def rot_center(self, image, angle):\n",
        "        orig_rect = image.get_rect()\n",
        "        rot_image = pygame.transform.rotate(image, angle)\n",
        "        rot_rect = orig_rect.copy()\n",
        "        rot_rect.center = rot_image.get_rect().center\n",
        "        rot_image = rot_image.subsurface(rot_rect).copy()\n",
        "        return rot_image\n",
        "\n",
        "class Walker(Env):\n",
        "    def __init__(self):\n",
        "        self.action_space = MultiDiscrete([3]*8)\n",
        "        self.observation_space = Box(-20,20,[8])\n",
        "        self.viewer = None\n",
        "        self.last_horizontal_pos = 0\n",
        "        self.last_vertical_pos = 0\n",
        "  \n",
        "    def step(self, actions):\n",
        "        actions = [(a-1)*5 for a in actions]\n",
        "        self.robot.ru_motor.rate = actions[0]\n",
        "        self.robot.rd_motor.rate = actions[1]\n",
        "        self.robot.lu_motor.rate = actions[2]\n",
        "        self.robot.ld_motor.rate = actions[3]\n",
        "        self.robot.la_motor.rate = actions[4]\n",
        "        self.robot.ra_motor.rate = actions[5]\n",
        "        self.robot.lf_motor.rate = actions[6]\n",
        "        self.robot.rf_motor.rate = actions[7]\n",
        "\n",
        "        self.robot.update()\n",
        "        self.space.step(1/50.0)\n",
        "\n",
        "\n",
        "        self.robot.ru_motor.rate = 0\n",
        "        self.robot.rd_motor.rate = 0\n",
        "        self.robot.lu_motor.rate = 0\n",
        "        self.robot.ld_motor.rate = 0\n",
        "        self.robot.la_motor.rate = 0\n",
        "        self.robot.ra_motor.rate = 0\n",
        "        self.robot.lf_motor.rate = 0\n",
        "        self.robot.rf_motor.rate = 0\n",
        "\n",
        "        done = False\n",
        "        if self.robot.body.position[0] < 0 or self.robot.body.position[0] > screen_width:\n",
        "            done = True\n",
        "        if self.robot.body.position[1] <200:\n",
        "            done = True\n",
        "\n",
        "        reward = ((self.robot.body.position[0]))/100\n",
        "\n",
        "        info = {}\n",
        "        observation = (\n",
        "            self.robot.ru_body.angle,\n",
        "            self.robot.rd_body.angle,\n",
        "            self.robot.lu_body.angle,\n",
        "            self.robot.ld_body.angle,\n",
        "            self.robot.left_arm_upper_body.angle,\n",
        "            self.robot.right_arm_upper_body.angle,\n",
        "            self.robot.lf_body.angle,\n",
        "            self.robot.rf_body.angle\n",
        "        )\n",
        "\n",
        "        return(\n",
        "        observation,\n",
        "        reward,\n",
        "        done,\n",
        "        info)\n",
        "\n",
        "    def render(self):\n",
        "        if self.viewer is None:\n",
        "            self.viewer = pygame.init()\n",
        "            pymunk.pygame_util.positive_y_is_up = True\n",
        "            self.screen = pygame.display.set_mode((screen_width, screen_height))\n",
        "            self.clock = pygame.time.Clock()\n",
        "        self.draw_options = pymunk.pygame_util.DrawOptions(self.screen)\n",
        "        self.font = pygame.font.SysFont(\"Arial\", 30)\n",
        "        self.screen.fill((255, 255, 255))\n",
        "        self.space.debug_draw(self.draw_options)\n",
        "        pygame.display.flip()\n",
        "        self.clock.tick(60)\n",
        "        return pygame.surfarray.array3d(self.screen)\n",
        "\n",
        "        \n",
        "    def reset(self):\n",
        "        self.space = pymunk.Space()\n",
        "        self.space.gravity = (0.0, -990)\n",
        "\n",
        "        self.robot = Robot(self.space)\n",
        "        self.robot.add_land(self.space)\n",
        "        self.last_horizontal_pos = self.robot.body.position[0]\n",
        "        self.last_vertical_pos = self.robot.body.position[1]\n",
        "\n",
        "        observation = (\n",
        "            self.robot.ru_body.angle,\n",
        "            self.robot.rd_body.angle,\n",
        "            self.robot.lu_body.angle,\n",
        "            self.robot.ld_body.angle,\n",
        "            self.robot.left_arm_upper_body.angle,\n",
        "            self.robot.right_arm_upper_body.angle,\n",
        "            self.robot.lf_body.angle,\n",
        "            self.robot.rf_body.angle\n",
        "        )\n",
        "        return(observation)\n",
        "\n"
      ],
      "metadata": {
        "id": "k_dYt_xGU0Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-90A_MBZUkx4"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE6XBAieUkx5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Configuration paramaters for the whole setup\n",
        "seed = 42 # @param {type:\"integer\"}\n",
        "gamma = 0.99  # @param {type:\"number\"} # Discount factor for past rewards\n",
        "epsilon = 1.0 # @param {type:\"number\"} # Epsilon greedy parameter\n",
        "epsilon_min = 0.01 # @param {type:\"number\"} # Minimum epsilon greedy parameter\n",
        "epsilon_max = 1.0 # @param {type:\"number\"} # Maximum epsilon greedy parameter\n",
        "epsilon_interval = (\n",
        "    epsilon_max - epsilon_min\n",
        ")  # Rate at which to reduce chance of random action being taken\n",
        "batch_size = 20 # @param {type:\"integer\"} # Size of batch taken from replay buffer\n",
        "units = 128 # @param{type:\"integer\"}\n",
        "learning_rate = 0.001 # @param{type:\"number\"}\n",
        "target_reward = 400.0 # @param{type:\"number\"}\n",
        "win_trials = 100 # @param{type:\"integer\"}\n",
        "nr_episodes =  300# @param{type:\"integer\"}\n",
        "loss = \"mae\" # @param{type:\"string\"}\n",
        "env = Walker()\n",
        "\n",
        "\n",
        "states = env.observation_space.shape\n",
        "actions = 8*3 \n",
        "\n",
        "run = wandb.init(\n",
        "    config={\n",
        "        \"gamma\": gamma, \n",
        "        \"epsilon\": epsilon,\n",
        "        \"epsilon_min\": epsilon_min,\n",
        "        \"target_reward\": target_reward,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"win_trials\": win_trials,\n",
        "        \"units\": units,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"loss\": loss,\n",
        "        \"nr_episodes\": nr_episodes\n",
        "        },\n",
        "    project=\"walker-v1\")\n",
        "base_path += f\"{run.project}-{run.name}/\"\n",
        "os.mkdir(base_path, 0o666)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpPMLzCXUkx7"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhtqewI4Ukx7"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "        # Define model layers.\n",
        "    units = run.config.units\n",
        "    input_layer = Input(8,1)\n",
        "    first_dense = Dense(units=units, activation='relu')(input_layer)\n",
        "    # Y1 output will be fed from the first dense\n",
        "    y1_output = Dense(units='3', name='motor_1')(first_dense)\n",
        "\n",
        "    second_dense = Dense(units=units,activation='relu')(first_dense)\n",
        "    # Y2 output will be fed from the second dense\n",
        "    y2_output = Dense(units='3',name='motor_2')(second_dense)\n",
        "\n",
        "    third_dense = Dense(units=units,activation='relu')(second_dense)\n",
        "    # Y2 output will be fed from the second dense\n",
        "    y3_output = Dense(units='3',name='motor_3')(third_dense)\n",
        "\n",
        "    four_dense = Dense(units=units,activation='relu')(third_dense)\n",
        "    # Y2 output will be fed from the second dense\n",
        "    y4_output = Dense(units='3',name='motor_4')(four_dense)\n",
        "\n",
        "    five_dense = Dense(units=units,activation='relu')(four_dense)\n",
        "    # Y2 output will be fed from the second dense\n",
        "    y5_output = Dense(units='3',name='motor_5')(five_dense)\n",
        "\n",
        "    six_dense = Dense(units=units,activation='relu')(five_dense)\n",
        "    # Y2 output will be fed from the second dense\n",
        "    y6_output = Dense(units='3',name='motor_6')(six_dense)\n",
        "\n",
        "    seven_dense = Dense(units=units,activation='relu')(six_dense)\n",
        "    # Y2 output will be fed from the second dense\n",
        "    y7_output = Dense(units='3',name='motor_7')(seven_dense)\n",
        "\n",
        "    eight_dense = Dense(units=units,activation='relu')(seven_dense)\n",
        "    # Y2 output will be fed from the second dense\n",
        "    y8_output = Dense(units='3',name='motor_8')(eight_dense)\n",
        "\n",
        "    # Define the model with the input layer \n",
        "    # and a list of output layers\n",
        "    model = Model(inputs=input_layer,outputs=[y1_output, y2_output, y3_output,y4_output,y5_output,y6_output,y7_output,y8_output])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hHQcg35Ukx-"
      },
      "source": [
        "# DQN Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiN2AZPCUkx-"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self,\n",
        "                 state_space, \n",
        "                 action_space, \n",
        "                 episodes=500,\n",
        "                 weights = None):\n",
        "        \"\"\"DQN Agent on CartPole-v0 environment\n",
        "\n",
        "        Arguments:\n",
        "            state_space (tensor): state space\n",
        "            action_space (tensor): action space\n",
        "            episodes (int): number of episodes to train\n",
        "        \"\"\"\n",
        "        self.action_space = action_space\n",
        "\n",
        "        # experience buffer\n",
        "        self.memory = []\n",
        "        # discount rate\n",
        "        self.gamma = run.config.gamma\n",
        "\n",
        "        # initially 90% exploration, 10% exploitation\n",
        "        self.epsilon = run.config.epsilon\n",
        "        # iteratively applying decay til \n",
        "        # 10% exploration/90% exploitation\n",
        "        self.epsilon_min = run.config.epsilon_min\n",
        "        self.epsilon_decay = self.epsilon_min / self.epsilon\n",
        "        self.epsilon_decay = self.epsilon_decay ** \\\n",
        "                             (1. / float(episodes))\n",
        "        if weights != None:\n",
        "          self.load_weights(weights)\n",
        "\n",
        "                \n",
        "        self.q_model = build_model()\n",
        "        self.q_model.compile(loss=run.config.loss, optimizer=Adam(learning_rate=run.config.learning_rate))\n",
        "        # target Q Network\n",
        "        self.target_q_model = build_model()\n",
        "        # copy Q Network params to target Q Network\n",
        "        self.update_weights()\n",
        "\n",
        "        self.replay_counter = 0\n",
        "\n",
        "\n",
        "    def save_weights(self, episode):\n",
        "        \"\"\"save Q Network params to a file\"\"\"\n",
        "        self.q_model.save_weights(f'{base_path}{episode}-steps.h5')\n",
        "        \n",
        "    def update_weights(self):\n",
        "        \"\"\"copy trained Q Network params to target Q Network\"\"\"\n",
        "        self.target_q_model.set_weights(self.q_model.get_weights())\n",
        "\n",
        "    def load_weights(self, path):\n",
        "        self.q_model.load_weights(path)\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"eps-greedy policy\n",
        "        Return:\n",
        "            action (tensor): action to execute\n",
        "        \"\"\"\n",
        "        \n",
        "        if np.random.rand() < self.epsilon:\n",
        "            # explore - do random action\n",
        "            return self.action_space.sample()\n",
        "        # exploit\n",
        "        state = np.expand_dims(state,0)\n",
        "        \n",
        "        q_values = self.q_model.predict(state)\n",
        "        # select the action with max Q-value\n",
        "        action = np.argmax(q_values, axis=2).flatten()\n",
        "        return action\n",
        "\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        \"\"\"store experiences in the replay buffer\n",
        "        Arguments:\n",
        "            state (tensor): env state\n",
        "            action (tensor): agent action\n",
        "            reward (float): reward received after executing\n",
        "                action on state\n",
        "            next_state (tensor): next state\n",
        "        \"\"\"\n",
        "        item = (state, action, reward, next_state, done)\n",
        "        self.memory.append(item)\n",
        "\n",
        "\n",
        "    def get_target_q_value(self, next_state, reward):\n",
        "        \"\"\"compute Q_max\n",
        "           Use of target Q Network solves the \n",
        "            non-stationarity problem\n",
        "        Arguments:\n",
        "            reward (float): reward received after executing\n",
        "                action on state\n",
        "            next_state (tensor): next state\n",
        "        Return:\n",
        "            q_value (float): max Q-value computed\n",
        "        \"\"\"\n",
        "        # max Q value among next state's actions\n",
        "        # DQN chooses the max Q value among next actions\n",
        "        # selection and evaluation of action is \n",
        "        # on the target Q Network\n",
        "        # Q_max = max_a' Q_target(s', a')\n",
        "        next_state = np.expand_dims(next_state,0)\n",
        "        q_values = self.target_q_model.predict(next_state)\n",
        "        q_value = np.amax(self.target_q_model.predict(next_state), axis=2)\n",
        "\n",
        "        # Q_max = reward + gamma * Q_max\n",
        "        q_value *= self.gamma\n",
        "        q_value += reward\n",
        "        return q_value\n",
        "\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        \"\"\"experience replay addresses the correlation issue \n",
        "            between samples\n",
        "        Arguments:\n",
        "            batch_size (int): replay buffer batch \n",
        "                sample size\n",
        "        \"\"\"\n",
        "        # sars = state, action, reward, state' (next_state)\n",
        "        sars_batch = sample(self.memory, batch_size)\n",
        "        state_batch, q_values_batch = [], []\n",
        "\n",
        "        # fixme: for speedup, this could be done on the tensor level\n",
        "        # but easier to understand using a loop\n",
        "        for state, action, reward, next_state, done in sars_batch:\n",
        "            # policy prediction for a given state\n",
        "            state = np.expand_dims(state,0)\n",
        "            q_values = self.q_model.predict(state)\n",
        "            \n",
        "            # get Q_max\n",
        "            q_value = self.get_target_q_value(next_state, reward)\n",
        "            # correction on the Q value for the action used\n",
        "            for i in q_values:\n",
        "\n",
        "              i[0][action] = [reward]*8 if done else q_value.flatten()\n",
        "            #q_values[0][action] = reward if done else q_value\n",
        "\n",
        "            # collect batch state-q_value mapping\n",
        "            state_batch.append(state[0])\n",
        "            q_values_batch.append(q_values[0])\n",
        "\n",
        "        # train the Q-network\n",
        "        self.q_model.fit(np.array(state_batch),\n",
        "                         np.array(q_values_batch),\n",
        "                         batch_size=batch_size,\n",
        "                         verbose=0,\n",
        "                         epochs=1,\n",
        "                         callbacks=[WandbCallback()])\n",
        "                \n",
        "\n",
        "        # update exploration-exploitation probability\n",
        "        self.update_epsilon()\n",
        "        # copy new params on old target after \n",
        "        # every 10 training updates\n",
        "        if self.replay_counter % 10 == 0:\n",
        "            self.update_weights()\n",
        "\n",
        "        self.replay_counter += 1\n",
        "\n",
        "    \n",
        "    def update_epsilon(self):\n",
        "        \"\"\"decrease the exploration, increase exploitation\"\"\"\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video"
      ],
      "metadata": {
        "id": "5Cx8Mi9hklSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "def create_policy_eval_video(filename, num_episodes=1, fps=30):\n",
        "  filename = base_path +filename + \".mp4\"\n",
        "  with imageio.get_writer(filename, fps=fps) as video:\n",
        "    for _ in range(num_episodes):\n",
        "      state = env.reset()\n",
        "      video.append_data(env.render())\n",
        "      done = False\n",
        "      while not done:\n",
        "        state = np.expand_dims(state,0)\n",
        "        q_values = agent.q_model.predict(state)\n",
        "        action = np.argmax(q_values, axis=2).flatten()\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        video.append_data(env.render())\n",
        "  run.log(\n",
        "  {\"video\": wandb.Video(filename, fps=30, format=\"mp4\")})"
      ],
      "metadata": {
        "id": "ADu8Qn7skkhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sntjsoDvUkyA"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e-G1nL8YUkyA"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    \n",
        "\n",
        "    # the number of trials without falling over\n",
        "    win_trials = run.config.win_trials\n",
        "    # the CartPole-v0 is considered solved if \n",
        "    # for 100 consecutive trials, he cart pole has not \n",
        "    # fallen over and it has achieved an average \n",
        "    # reward of 195.0 \n",
        "    # a reward of +1 is provided for every timestep \n",
        "    # the pole remains upright\n",
        "\n",
        "    # stores the reward per episode\n",
        "    scores = deque(maxlen=win_trials)\n",
        "    rewards_history_full = []\n",
        "    logger.setLevel(logger.ERROR)\n",
        "    env = Walker()\n",
        "\n",
        "    #env.seed(0)\n",
        "\n",
        "    # instantiate the DQN/DDQN agent\n",
        "\n",
        "    agent = DQNAgent(env.observation_space, env.action_space, run.config.nr_episodes)\n",
        "\n",
        "    # should be solved in this number of episodes\n",
        "    state_size = env.observation_space.shape[0]\n",
        "    batch_size = run.config.batch_size\n",
        "\n",
        "    # by default, CartPole-v1 has max episode steps = 500\n",
        "    # you can use this to experiment beyond 500\n",
        "    # env._max_episode_steps = 4000\n",
        "\n",
        "    # Q-Learning sampling and fitting\n",
        "    for episode in range(run.config.nr_episodes):\n",
        "        state = env.reset()\n",
        "        state = state\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        step_count = 0\n",
        "        reward_history = []\n",
        "        while not done:\n",
        "            # in CartPole-v0, action=0 is left and action=1 is right\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            #env.render()\n",
        "            # in CartPole-v0:\n",
        "            # state = [pos, vel, theta, angular speed]\n",
        "            next_state = next_state\n",
        "            # store every experience unit in replay buffer\n",
        "            agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            step_count += 1\n",
        "            reward_history.append(reward)\n",
        "        rewards_history_full.append(total_reward)\n",
        "        run.log({\n",
        "            \"reward\":total_reward,\n",
        "            \"epsilon\":agent.epsilon,\n",
        "            \"average reward\":np.average(reward_history)\n",
        "            })\n",
        "\n",
        "        # call experience relay\n",
        "        if len(agent.memory) >= batch_size:\n",
        "            agent.replay(batch_size)\n",
        "        scores.append(total_reward)\n",
        "        mean_score = np.mean(scores)\n",
        "        if mean_score >= run.config.target_reward \\\n",
        "                and episode >= win_trials:\n",
        "            print(\"Solved in episode %d: \\\n",
        "                   Mean survival = %0.2lf in %d episodes\"\n",
        "                  % (episode, mean_score, win_trials))\n",
        "            print(\"Epsilon: \", agent.epsilon)\n",
        "            break\n",
        "        if (episode + 1) % win_trials == 0:\n",
        "            print(\"Episode %d: Mean survival = \\\n",
        "                   %0.2lf in %d episodes\" %\n",
        "                  ((episode + 1), mean_score, win_trials))\n",
        "            agent.save_weights(episode)\n",
        "            \n",
        "    create_policy_eval_video(f\"{episode}-episodes\")\n",
        "    env.close() \n",
        "    run.save(f'{base_path}{episode}-steps.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "sweep_configuration = {\n",
        "    \"name\": \"my-awesome-sweep\",\n",
        "    \"metric\": {\"name\": \"reward\", \"goal\": \"maximize\"},\n",
        "    \"method\": \"grid\",\n",
        "    \"parameters\": {\n",
        "        \"learning_rate\" :{\n",
        "        \"min\": 0.0001,\n",
        "        \"max\": 0.1,\n",
        "         \"distribution\": \"q_uniform\"\n",
        "    },\n",
        "    \"nr_episodes\" :{\n",
        "        \"max\": 300,\n",
        "        \"min\": 50\n",
        "    },\n",
        "    \"batch_size\" :{\n",
        "        \"max\": 40,\n",
        "        \"min\": 10\n",
        "    },\n",
        "    \"units\" :{\n",
        "        \"max\": 256,\n",
        "        \"min\": 32\n",
        "    },\n",
        "    \"gama\":{\n",
        "        \"max\":0.99,\n",
        "        \"min\":0.7,\n",
        "        \"distribution\": \"q_uniform\"\n",
        "    }\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_configuration)\n",
        "\n",
        "# run the sweep\n",
        "wandb.agent(sweep_id, function=train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUy394E1uMEN",
        "outputId": "3806a66f-35b7-47b3-c888-4fa318238d0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: laqmwyc9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgama: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: mw2jcj4o\n",
            "Sweep URL: https://wandb.ai/sudofork/uncategorized/sweeps/mw2jcj4o\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnr_episodes: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n",
            "Run laqmwyc9 errored: NameError(\"name 'run' is not defined\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run laqmwyc9 errored: NameError(\"name 'run' is not defined\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 196ysn7z with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgama: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnr_episodes: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 33\n",
            "Run 196ysn7z errored: NameError(\"name 'run' is not defined\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 196ysn7z errored: NameError(\"name 'run' is not defined\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a131500f6664666dd459dcc63d270fb7b4d21f27357580e425cf19c89539d686"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "walker-keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ktnsHlqqOMm6",
        "HpPMLzCXUkx7",
        "5Cx8Mi9hklSB"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}